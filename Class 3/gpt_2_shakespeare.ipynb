{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Source: \n",
        "\n",
        "*   https://pypi.org/project/gpt-2-simple/#description\n",
        "*   https://medium.com/@stasinopoulos.dimitrios/a-beginners-guide-to-training-and-generating-text-using-gpt2-c2f2e1fbd10a\n",
        "*   https://colab.research.google.com/drive/1VLG8e7YSEwypxU-noRNhsv5dW4NfTGce#scrollTo=VHdTL8NDbAh3\n",
        "*  https://github.com/ak9250/gpt-2-colab\n",
        "*  https://www.aiweirdness.com/d-and-d-character-bios-now-making-19-03-15/\n",
        "*  https://minimaxir.com/2019/09/howto-gpt2/\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "rgNM-NcAZ9aT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/zawemi/GS2DIT/blob/main/Class%203/gpt_2_shakespeare.ipynb#scrollTo=4tIUvFbLMUuE)"
      ],
      "metadata": {
        "id": "4tIUvFbLMUuE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Let's teach AI writing like a Shakespeare ðŸŽ“"
      ],
      "metadata": {
        "id": "MofLJqBHAWXI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Installing the model"
      ],
      "metadata": {
        "id": "W7wiPFGQQn9o"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQACJ8lyUIR0",
        "outputId": "b4945da0-7212-4e89-fd3d-99576c973fca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting gpt-2-simple\n",
            "  Downloading gpt_2_simple-0.8.1.tar.gz (26 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tensorflow>=2.5.1 in /usr/local/lib/python3.9/dist-packages (from gpt-2-simple) (2.11.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.9/dist-packages (from gpt-2-simple) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from gpt-2-simple) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from gpt-2-simple) (4.65.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from gpt-2-simple) (1.22.4)\n",
            "Collecting toposort\n",
            "  Downloading toposort-1.10-py3-none-any.whl (8.5 kB)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (1.6.3)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (1.15.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (3.19.6)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (23.3.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (1.16.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (0.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (63.4.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (2.11.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (23.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (0.2.0)\n",
            "Requirement already satisfied: keras<2.12,>=2.11.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (2.11.0)\n",
            "Requirement already satisfied: tensorboard<2.12,>=2.11 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (2.11.2)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (0.31.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (1.51.3)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (15.0.6.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (3.3.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (3.8.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (1.4.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (2.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (4.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->gpt-2-simple) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->gpt-2-simple) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->gpt-2-simple) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->gpt-2-simple) (3.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.9/dist-packages (from astunparse>=1.6.0->tensorflow>=2.5.1->gpt-2-simple) (0.40.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.5.1->gpt-2-simple) (0.4.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.5.1->gpt-2-simple) (2.16.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.5.1->gpt-2-simple) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.5.1->gpt-2-simple) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.5.1->gpt-2-simple) (2.2.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.5.1->gpt-2-simple) (3.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow>=2.5.1->gpt-2-simple) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow>=2.5.1->gpt-2-simple) (0.2.8)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow>=2.5.1->gpt-2-simple) (5.3.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow>=2.5.1->gpt-2-simple) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/dist-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow>=2.5.1->gpt-2-simple) (6.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.9/dist-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow>=2.5.1->gpt-2-simple) (2.1.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow>=2.5.1->gpt-2-simple) (3.15.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow>=2.5.1->gpt-2-simple) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow>=2.5.1->gpt-2-simple) (3.2.2)\n",
            "Building wheels for collected packages: gpt-2-simple\n",
            "  Building wheel for gpt-2-simple (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gpt-2-simple: filename=gpt_2_simple-0.8.1-py3-none-any.whl size=24576 sha256=899e3ab4ec606cf083e09a2ae1f99d9da01cf2ae69189cf9295a9d30907e2862\n",
            "  Stored in directory: /root/.cache/pip/wheels/4e/28/f0/2f12e470be10d6804b193e4193d274c88995010fae512a67cf\n",
            "Successfully built gpt-2-simple\n",
            "Installing collected packages: toposort, gpt-2-simple\n",
            "Successfully installed gpt-2-simple-0.8.1 toposort-1.10\n"
          ]
        }
      ],
      "source": [
        "#install the library we'll use today\n",
        "!pip install gpt-2-simple"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Generating text with basic model"
      ],
      "metadata": {
        "id": "ADzeFwzaQ8cT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Importing and loading necessary components"
      ],
      "metadata": {
        "id": "d6Ah3D1CRK6o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import what we need\n",
        "import gpt_2_simple as gpt2 #for gpt-2 (our AI model)\n",
        "import os #lets us doing things with files and folders\n",
        "import requests #this one helps to dowload from the internet"
      ],
      "metadata": {
        "id": "mLg4pTPDaJJV"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#and let's download our AI model\n",
        "gpt2.download_gpt2()   # model is saved into current directory under /models/124M/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fIXHjaxvaWsV",
        "outputId": "38023063-8a2c-4ce2-cb89-fec8beb0778d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching checkpoint: 1.05Mit [00:00, 500Mit/s]                                                      \n",
            "Fetching encoder.json: 1.05Mit [00:00, 3.08Mit/s]\n",
            "Fetching hparams.json: 1.05Mit [00:00, 688Mit/s]                                                    \n",
            "Fetching model.ckpt.data-00000-of-00001: 498Mit [01:04, 7.74Mit/s]\n",
            "Fetching model.ckpt.index: 1.05Mit [00:00, 478Mit/s]                                                \n",
            "Fetching model.ckpt.meta: 1.05Mit [00:00, 4.22Mit/s]\n",
            "Fetching vocab.bpe: 1.05Mit [00:00, 4.26Mit/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#strating the session so we can play with the gpt-2 model\n",
        "sess = gpt2.start_tf_sess()"
      ],
      "metadata": {
        "id": "6CCkn75KbBpg"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#we load the model from file to use it\n",
        "gpt2.load_gpt2(sess, run_name='124M', checkpoint_dir='models')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nsBvHQsxZsyP",
        "outputId": "77eb0a7a-e5bb-4123-d418-22585355c59a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading checkpoint models/124M/model.ckpt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Text generation"
      ],
      "metadata": {
        "id": "mDSFDj78RQJg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#this is how we would start model statement\n",
        "prefix = \"What is after death?\""
      ],
      "metadata": {
        "id": "-P5_fxZOgGlk"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#the model is generating text\n",
        "gpt2.generate(sess, run_name='124M', checkpoint_dir='models', prefix=prefix, length=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qSYqTat0gNDo",
        "outputId": "b8c64d01-23dc-40f4-e952-a6f188c619ce"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What is after death?\"\n",
            "\n",
            "He said, \"I will tell you in my dream, I am a little boy, and I will live until death. I have been in nature for thousands of years, but I will have no children. I will have no children\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Generating text with improved (finetuned) model"
      ],
      "metadata": {
        "id": "ML5helfmRjT0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**IMPORTANT**\n",
        "</br>Restart the runtime (Runtime -> Restart runtime)"
      ],
      "metadata": {
        "id": "8cEaZKtRPx0S"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NogbQIc1flh7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Importing and loading necessary components"
      ],
      "metadata": {
        "id": "NIPDKskeR7i3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import what we need\n",
        "import gpt_2_simple as gpt2 #for gpt-2 (our AI model)\n",
        "import os #lets us doing things with files and folders\n",
        "import requests #this one helps to dowload from the internet"
      ],
      "metadata": {
        "id": "eHys5-bWPnhJ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#get nietzsche texts\n",
        "!wget \"https://s3.amazonaws.com/text-datasets/nietzsche.txt\""
      ],
      "metadata": {
        "id": "dRTQyR7IqaOl",
        "outputId": "c280b68f-1eb3-4872-aefa-95a0954ab8c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-22 13:24:57--  https://s3.amazonaws.com/text-datasets/nietzsche.txt\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 54.231.228.24, 52.217.118.184, 52.217.17.110, ...\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|54.231.228.24|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 600901 (587K) [text/plain]\n",
            "Saving to: â€˜nietzsche.txtâ€™\n",
            "\n",
            "nietzsche.txt       100%[===================>] 586.82K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2023-03-22 13:24:57 (5.76 MB/s) - â€˜nietzsche.txtâ€™ saved [600901/600901]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#game of thrones from https://www.kaggle.com/datasets/khulasasndh/game-of-thrones-books?select=001ssb.txt\n",
        "!gdown \"1CrL1wde_NGO68i5Prd_UNA_oW0cGQsxg&confirm=t\"\n",
        "!mv /content/001ssb.txt /content/got1.txt"
      ],
      "metadata": {
        "id": "pzDNTjJzuKDW",
        "outputId": "b82787f7-fe3e-49c8-d229-b4e75e515e2f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1CrL1wde_NGO68i5Prd_UNA_oW0cGQsxg&confirm=t\n",
            "To: /content/001ssb.txt\n",
            "\r  0% 0.00/1.63M [00:00<?, ?B/s]\r100% 1.63M/1.63M [00:00<00:00, 185MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#let's dowload a file with all Shakespeare plays\n",
        "!wget \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\"\n",
        "!mv /content/input.txt /content/shakespeare.txt"
      ],
      "metadata": {
        "id": "9pwWGn5eqBJn",
        "outputId": "3669a286-ca36-4932-a0c4-4f23df07c848",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-22 13:25:20--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115394 (1.1M) [text/plain]\n",
            "Saving to: â€˜input.txtâ€™\n",
            "\n",
            "\rinput.txt             0%[                    ]       0  --.-KB/s               \rinput.txt           100%[===================>]   1.06M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2023-03-22 13:25:20 (20.8 MB/s) - â€˜input.txtâ€™ saved [1115394/1115394]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#strating the session so we can play with the gpt-2 model\n",
        "sess = gpt2.start_tf_sess()"
      ],
      "metadata": {
        "id": "A0T2s8RxPnVr"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Teaching our model"
      ],
      "metadata": {
        "id": "bvllQvFxR9z6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#finetuning with shakespeare.txt (which, to be honest, means that we are teaching the model how to write like a shakespeare)\n",
        "#it takes a lot of time (~15min)...\n",
        "gpt2.finetune(sess, 'got1.txt', steps=500)   # steps is max number of training steps"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2RJetxF6UOfY",
        "outputId": "f813528f-3824-4aa8-8852-2e491dc48928"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading checkpoint models/124M/model.ckpt\n",
            "Loading dataset...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.81s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset has 433157 tokens\n",
            "Training...\n",
            "[1 | 7.38] loss=3.46 avg=3.46\n",
            "[2 | 9.51] loss=3.39 avg=3.42\n",
            "[3 | 11.65] loss=3.25 avg=3.37\n",
            "[4 | 13.79] loss=3.37 avg=3.37\n",
            "[5 | 15.94] loss=3.35 avg=3.36\n",
            "[6 | 18.09] loss=3.30 avg=3.35\n",
            "[7 | 20.25] loss=3.21 avg=3.33\n",
            "[8 | 22.42] loss=3.33 avg=3.33\n",
            "[9 | 24.59] loss=3.13 avg=3.31\n",
            "[10 | 26.77] loss=3.33 avg=3.31\n",
            "[11 | 28.95] loss=3.20 avg=3.30\n",
            "[12 | 31.13] loss=3.24 avg=3.29\n",
            "[13 | 33.33] loss=3.17 avg=3.28\n",
            "[14 | 35.53] loss=3.15 avg=3.27\n",
            "[15 | 37.76] loss=3.16 avg=3.27\n",
            "[16 | 40.03] loss=3.17 avg=3.26\n",
            "[17 | 42.25] loss=3.15 avg=3.25\n",
            "[18 | 44.49] loss=2.97 avg=3.23\n",
            "[19 | 46.74] loss=3.03 avg=3.22\n",
            "[20 | 48.99] loss=3.08 avg=3.22\n",
            "[21 | 51.26] loss=3.16 avg=3.21\n",
            "[22 | 53.52] loss=3.18 avg=3.21\n",
            "[23 | 55.79] loss=3.09 avg=3.20\n",
            "[24 | 58.07] loss=3.02 avg=3.20\n",
            "[25 | 60.36] loss=3.07 avg=3.19\n",
            "[26 | 62.66] loss=3.06 avg=3.18\n",
            "[27 | 64.94] loss=3.09 avg=3.18\n",
            "[28 | 67.22] loss=3.06 avg=3.18\n",
            "[29 | 69.49] loss=3.07 avg=3.17\n",
            "[30 | 71.76] loss=3.11 avg=3.17\n",
            "[31 | 74.01] loss=2.93 avg=3.16\n",
            "[32 | 76.27] loss=2.96 avg=3.15\n",
            "[33 | 78.51] loss=3.06 avg=3.15\n",
            "[34 | 80.75] loss=3.10 avg=3.15\n",
            "[35 | 82.99] loss=3.06 avg=3.14\n",
            "[36 | 85.22] loss=3.09 avg=3.14\n",
            "[37 | 87.45] loss=3.14 avg=3.14\n",
            "[38 | 89.67] loss=3.11 avg=3.14\n",
            "[39 | 91.89] loss=2.97 avg=3.14\n",
            "[40 | 94.10] loss=3.10 avg=3.14\n",
            "[41 | 96.32] loss=3.01 avg=3.13\n",
            "[42 | 98.53] loss=2.98 avg=3.13\n",
            "[43 | 100.74] loss=3.03 avg=3.12\n",
            "[44 | 102.95] loss=2.95 avg=3.12\n",
            "[45 | 105.16] loss=3.12 avg=3.12\n",
            "[46 | 107.37] loss=2.99 avg=3.12\n",
            "[47 | 109.57] loss=2.98 avg=3.11\n",
            "[48 | 111.79] loss=3.00 avg=3.11\n",
            "[49 | 114.01] loss=2.93 avg=3.10\n",
            "[50 | 116.24] loss=3.03 avg=3.10\n",
            "[51 | 118.46] loss=3.02 avg=3.10\n",
            "[52 | 120.68] loss=2.96 avg=3.10\n",
            "[53 | 122.90] loss=2.82 avg=3.09\n",
            "[54 | 125.13] loss=3.02 avg=3.09\n",
            "[55 | 127.37] loss=2.80 avg=3.08\n",
            "[56 | 129.60] loss=2.96 avg=3.08\n",
            "[57 | 131.84] loss=3.12 avg=3.08\n",
            "[58 | 134.09] loss=2.91 avg=3.08\n",
            "[59 | 136.34] loss=3.06 avg=3.08\n",
            "[60 | 138.60] loss=2.95 avg=3.07\n",
            "[61 | 140.84] loss=3.09 avg=3.07\n",
            "[62 | 143.09] loss=2.89 avg=3.07\n",
            "[63 | 145.34] loss=3.02 avg=3.07\n",
            "[64 | 147.60] loss=2.76 avg=3.06\n",
            "[65 | 149.86] loss=2.95 avg=3.06\n",
            "[66 | 152.10] loss=2.87 avg=3.06\n",
            "[67 | 154.35] loss=3.01 avg=3.05\n",
            "[68 | 156.60] loss=2.95 avg=3.05\n",
            "[69 | 158.85] loss=2.93 avg=3.05\n",
            "[70 | 161.11] loss=3.03 avg=3.05\n",
            "[71 | 163.35] loss=3.04 avg=3.05\n",
            "[72 | 165.60] loss=2.80 avg=3.04\n",
            "[73 | 167.84] loss=2.80 avg=3.04\n",
            "[74 | 170.08] loss=2.89 avg=3.04\n",
            "[75 | 172.32] loss=2.93 avg=3.03\n",
            "[76 | 174.57] loss=2.85 avg=3.03\n",
            "[77 | 176.80] loss=2.91 avg=3.03\n",
            "[78 | 179.03] loss=2.80 avg=3.03\n",
            "[79 | 181.26] loss=2.92 avg=3.02\n",
            "[80 | 183.49] loss=2.76 avg=3.02\n",
            "[81 | 185.73] loss=3.00 avg=3.02\n",
            "[82 | 187.95] loss=3.07 avg=3.02\n",
            "[83 | 190.18] loss=2.86 avg=3.02\n",
            "[84 | 192.40] loss=2.97 avg=3.02\n",
            "[85 | 194.65] loss=3.04 avg=3.02\n",
            "[86 | 196.96] loss=2.96 avg=3.02\n",
            "[87 | 199.20] loss=2.87 avg=3.01\n",
            "[88 | 201.48] loss=2.81 avg=3.01\n",
            "[89 | 203.73] loss=2.89 avg=3.01\n",
            "[90 | 205.96] loss=2.75 avg=3.00\n",
            "[91 | 208.19] loss=2.78 avg=3.00\n",
            "[92 | 210.43] loss=2.83 avg=3.00\n",
            "[93 | 212.66] loss=3.01 avg=3.00\n",
            "[94 | 214.90] loss=2.74 avg=2.99\n",
            "[95 | 217.13] loss=2.89 avg=2.99\n",
            "[96 | 219.37] loss=2.92 avg=2.99\n",
            "[97 | 221.60] loss=2.87 avg=2.99\n",
            "[98 | 223.84] loss=2.80 avg=2.98\n",
            "[99 | 226.08] loss=2.84 avg=2.98\n",
            "[100 | 228.32] loss=2.91 avg=2.98\n",
            "======== SAMPLE 1 ========\n",
            "You to see? You want me to take off my mask?\"\n",
            "She gave a startled grunt. \"You want to see.\"\n",
            "Page 478\n",
            "\n",
            "The boy was grinning at Sansa-comely with her eyes. The wolf boy had a strange way with her. \n",
            "\"You should be a boy now,\" Sansa told him. He smiled a sly smile, and nodded. Sansa was startled to see their \n",
            "frowning. \n",
            "They stood around the fire, holding up a heavy plate. The boy's eyes widened at the thought. They were \n",
            "shaking now. \"You don't think so? You're not a boy. You think you're a girl!\" \n",
            "\"Yes, Sansa.\" The wolf boy's mouth was hard and hard. \"Don't pretend to me. Do you not like to hear a girl talk?\" \n",
            "Catelyn laughed. \"Just the two of us. We might be alone.\" Her brother was all but gone. \n",
            "\"I'll be with you later,\" he said pleasantly, smiling, \"but before that, please tell me where you find yourself.\" \n",
            "\"Is there a place for you on the island? Where do you find yourself?\" A strange sort of \n",
            "sweltering thought wriggled through Catelyn's mind. If she did find herself alone in the library, well, what would she say to \n",
            "them, anyway? Her father's dead? How would she say goodbye to him? \n",
            "Catelyn had no choice. She told her brother. \n",
            "The boy laughed, and suddenly Sansa knew she had given her mother a lesson. It did not seem he liked \n",
            "her. \n",
            "\"I'll go, then,\" she told him. \"I'll show you.\" Her sister followed suit. They drove off down the alley, \n",
            "through a big red gatehouse, past a small windowless alley, past a high stone \n",
            "walls, into the night. Only the sound of her mother's footsteps and her father's grave was heard. \n",
            "Her hand was shaking from the knock. \"You're afraid he's coming to fetch you?\" she asked, her voice \n",
            "cold as iron. \n",
            "\"I'm,\" Sansa said. \"The knight that day. The morning, the night.\" \n",
            "The boy had always seemed a little frightened to her at first, but by the third word she had spoken \n",
            "Page 479\n",
            "\n",
            "now he seemed much less so. Her father was standing behind her, with his mouth at the end of a thin \n",
            "stump, and his teeth were running up and down the side of her mouth. He would seem an ugly \n",
            "woman, or at least he wouldn't talk like a girl. And it frightened her now. It scared her to her titties; it \n",
            "seemed to make her shiver. It frightened her sisters, too, if only to herself. \"The other girls call him Snow.\" \n",
            "\"You'll see.\" Sansa heard her sister say that in vain, but he did smile, and she was laughing at herself \n",
            "now. They were laughing now now too, and her mother would never forgive her this way. She might \n",
            "not have ever thought that her brother could hear her laughing. They made up again, and she sat \n",
            "together in the doorway, her little eyes and them, and Sansa felt a fever, and felt the wetness against \n",
            "her skin. She'd been a girl in high school. It was an unnatural feeling, to be around him. He would \n",
            "never come in here. Maybe someday she had to be alone with him, somewhere. She could come, but not now. \n",
            "So, the next morning, she pushed her sister toward the exit window, and she could hear them laughing in the fire. \n",
            "They had come across her as soon as she started through the door behind the little window. She could hear them \n",
            "laughing, and hear how the Knight of Flowers had pulled his head up as she walked past. Sansa was certain that he \n",
            "hefted their laughter, and hefted it back and forth with each word. And they laughed, and he did. \n",
            "And she started off. Sansa started up, faster than she'd ever go; faster because she knew they would \n",
            "come. They always did. One of them was riding down the hall to meet her sister, she had told herself. Sansa \n",
            "might have taken off her cloak and drawn it down, had it been off. It was not the end of the world. She'd made \n",
            "her way to him, to be sure, but he seemed oddly clumsy. After she pushed him off her, she heard her sister's \n",
            "commanding voice say, \"Shall we walk back and forth? I've heard a few whispers.\" Sansa felt oddly stupid for \n",
            "prom\n",
            "\n",
            "[101 | 242.66] loss=2.83 avg=2.98\n",
            "[102 | 244.90] loss=2.61 avg=2.97\n",
            "[103 | 247.15] loss=2.63 avg=2.97\n",
            "[104 | 249.39] loss=2.78 avg=2.97\n",
            "[105 | 251.64] loss=2.85 avg=2.96\n",
            "[106 | 253.87] loss=2.71 avg=2.96\n",
            "[107 | 256.11] loss=2.80 avg=2.96\n",
            "[108 | 258.35] loss=2.82 avg=2.95\n",
            "[109 | 260.59] loss=2.83 avg=2.95\n",
            "[110 | 262.83] loss=2.48 avg=2.95\n",
            "[111 | 265.07] loss=2.76 avg=2.94\n",
            "[112 | 267.31] loss=2.90 avg=2.94\n",
            "[113 | 269.55] loss=2.77 avg=2.94\n",
            "[114 | 271.79] loss=2.83 avg=2.94\n",
            "[115 | 274.03] loss=2.79 avg=2.94\n",
            "[116 | 276.28] loss=2.68 avg=2.93\n",
            "[117 | 278.54] loss=2.69 avg=2.93\n",
            "[118 | 280.78] loss=2.66 avg=2.93\n",
            "[119 | 283.02] loss=2.65 avg=2.92\n",
            "[120 | 285.26] loss=2.74 avg=2.92\n",
            "[121 | 287.50] loss=2.88 avg=2.92\n",
            "[122 | 289.73] loss=2.91 avg=2.92\n",
            "[123 | 291.96] loss=2.70 avg=2.91\n",
            "[124 | 294.20] loss=2.62 avg=2.91\n",
            "[125 | 296.44] loss=2.91 avg=2.91\n",
            "[126 | 298.67] loss=2.88 avg=2.91\n",
            "[127 | 300.91] loss=2.68 avg=2.91\n",
            "[128 | 303.14] loss=2.64 avg=2.90\n",
            "[129 | 305.38] loss=2.73 avg=2.90\n",
            "[130 | 307.61] loss=2.68 avg=2.90\n",
            "[131 | 309.85] loss=2.83 avg=2.90\n",
            "[132 | 312.08] loss=2.85 avg=2.90\n",
            "[133 | 314.31] loss=2.77 avg=2.89\n",
            "[134 | 316.55] loss=2.62 avg=2.89\n",
            "[135 | 318.79] loss=2.65 avg=2.89\n",
            "[136 | 321.03] loss=2.67 avg=2.88\n",
            "[137 | 323.26] loss=2.80 avg=2.88\n",
            "[138 | 325.49] loss=2.51 avg=2.88\n",
            "[139 | 327.72] loss=2.69 avg=2.88\n",
            "[140 | 329.95] loss=2.58 avg=2.87\n",
            "[141 | 332.20] loss=2.80 avg=2.87\n",
            "[142 | 334.43] loss=2.76 avg=2.87\n",
            "[143 | 336.66] loss=2.82 avg=2.87\n",
            "[144 | 338.89] loss=2.75 avg=2.87\n",
            "[145 | 341.12] loss=2.82 avg=2.87\n",
            "[146 | 343.36] loss=2.81 avg=2.87\n",
            "[147 | 345.60] loss=2.82 avg=2.87\n",
            "[148 | 347.84] loss=2.78 avg=2.86\n",
            "[149 | 350.07] loss=2.77 avg=2.86\n",
            "[150 | 352.30] loss=2.57 avg=2.86\n",
            "[151 | 354.54] loss=2.77 avg=2.86\n",
            "[152 | 356.78] loss=2.61 avg=2.86\n",
            "[153 | 359.01] loss=2.70 avg=2.85\n",
            "[154 | 361.25] loss=2.65 avg=2.85\n",
            "[155 | 363.48] loss=2.81 avg=2.85\n",
            "[156 | 365.72] loss=2.86 avg=2.85\n",
            "[157 | 367.96] loss=2.56 avg=2.85\n",
            "[158 | 370.20] loss=2.68 avg=2.84\n",
            "[159 | 372.43] loss=2.49 avg=2.84\n",
            "[160 | 374.67] loss=2.60 avg=2.84\n",
            "[161 | 376.90] loss=2.58 avg=2.83\n",
            "[162 | 379.14] loss=2.47 avg=2.83\n",
            "[163 | 381.39] loss=2.80 avg=2.83\n",
            "[164 | 383.62] loss=2.67 avg=2.83\n",
            "[165 | 385.85] loss=2.76 avg=2.83\n",
            "[166 | 388.09] loss=2.39 avg=2.82\n",
            "[167 | 390.33] loss=2.80 avg=2.82\n",
            "[168 | 392.57] loss=2.83 avg=2.82\n",
            "[169 | 394.81] loss=2.61 avg=2.82\n",
            "[170 | 397.05] loss=2.69 avg=2.82\n",
            "[171 | 399.29] loss=2.82 avg=2.82\n",
            "[172 | 401.52] loss=2.58 avg=2.81\n",
            "[173 | 403.76] loss=2.64 avg=2.81\n",
            "[174 | 406.00] loss=2.62 avg=2.81\n",
            "[175 | 408.24] loss=2.60 avg=2.81\n",
            "[176 | 410.47] loss=2.43 avg=2.80\n",
            "[177 | 412.72] loss=2.50 avg=2.80\n",
            "[178 | 414.96] loss=2.60 avg=2.80\n",
            "[179 | 417.20] loss=2.65 avg=2.79\n",
            "[180 | 419.44] loss=2.43 avg=2.79\n",
            "[181 | 421.68] loss=2.51 avg=2.79\n",
            "[182 | 423.92] loss=2.61 avg=2.78\n",
            "[183 | 426.15] loss=2.46 avg=2.78\n",
            "[184 | 428.40] loss=2.53 avg=2.78\n",
            "[185 | 430.65] loss=2.74 avg=2.78\n",
            "[186 | 432.89] loss=2.54 avg=2.77\n",
            "[187 | 435.14] loss=2.77 avg=2.77\n",
            "[188 | 437.38] loss=2.66 avg=2.77\n",
            "[189 | 439.62] loss=2.41 avg=2.77\n",
            "[190 | 441.87] loss=2.66 avg=2.77\n",
            "[191 | 444.12] loss=2.53 avg=2.76\n",
            "[192 | 446.36] loss=2.51 avg=2.76\n",
            "[193 | 448.60] loss=2.43 avg=2.76\n",
            "[194 | 450.84] loss=2.73 avg=2.76\n",
            "[195 | 453.09] loss=2.52 avg=2.75\n",
            "[196 | 455.34] loss=2.80 avg=2.75\n",
            "[197 | 457.59] loss=2.84 avg=2.76\n",
            "[198 | 459.83] loss=2.39 avg=2.75\n",
            "[199 | 462.07] loss=2.59 avg=2.75\n",
            "[200 | 464.31] loss=2.65 avg=2.75\n",
            "======== SAMPLE 1 ========\n",
            " great blood from your manhood, you look like a child.\" \n",
            "Her brother nodded. \"I could not have said the same of you. I did not see my brother until he came \n",
            "of age, but you were no stranger to your people than the Others.\" He smiled. \"You will live as \n",
            "these children do.\" \n",
            "Sans smiled. \"As they did in their clans and kingdoms, my lord. I shall ride with you when you are grown \n",
            "enough to drink of water from the well.\" \n",
            "His brother stood in front of the altar of Pentes, his horse, and threw forth the cup where it should \n",
            "have been consumed, the white powder swirling in the air. \n",
            "\"I will not die,\" he said. \"Father, if you die, you die too. You make me promise you will never \n",
            "die, and yet, for the last time, if you die, we will not keep you a gift.\" He lifted his head \n",
            "and looked at his brother. \n",
            "He was half-blind as a leaf, his vision blinded by the sun. \"I am too young to bear a son until \n",
            "my father passes away,\" he whispered. \"Yet the Gods look on us as heroes, yet we are still you, \n",
            "your god, and I know you have given the son of your own son to the man whose birth you were \n",
            "waiting for. Do you suppose we shall keep you a gift?\" \n",
            "A sudden rumble came over the hearth and Ned looked around anxiously. He saw the faces of most of \n",
            "the guards who had been there, and he was frightened. \"Can they see me?\" he asked, struggling to keep his cool. \"Why?\" \n",
            "Ned gave a shuddering sound as his hand touched his forehead, felt the cold air on his hands and hands \n",
            "and legs. \"Is this your son?\" he sounded almost scared. He was still half-blind, half-blind now, only \n",
            "more frightened. \n",
            "They would not see him, he swore. \n",
            "Ned moved around the circle a bit, taking one step at a time. \"You may have to hurry \n",
            "up. The men have been leaving for the city. The city walls are still crusted with the footprints of \n",
            "the dead. What are you doing up here?\" \n",
            "A heavy iron ring went around a hole so large the hole was half a foot deep it made the ground \n",
            "shatter. He pushed himself up on his horse, riding with a lazy breath. The men were making no sound \n",
            "in the circle. Ned could feel cold wind and empty air on his legs and hands as he hopped. \"My \n",
            "friend?\" he asked as he caught sight of Bran. \n",
            "\"You'll be able to see me,\" Bran promised. The godswife pushed him over to one knee, one hand on \n",
            "heaving steel. \"Take a step, and see.\" \n",
            "Ned could feel a sweet and velvety breath on his face, warm to the touch and his heart beating faster. He \n",
            "wanted to be so high he wanted to ride. \"What are you doing?\" \n",
            "\"Shaving,\" the godswife said, smiling. \"Is this a thing for me?\" \n",
            "\"It's,\" Ned said, smiling back. \n",
            "The air was warm and heavy around them. Ned took a step back from where he lay. \"Sans, I'd best \n",
            "be a little nicer,\" the godswife announced. \"Bring the girls down from the castle. There's no better \n",
            "time than now, Father. It's time to \n",
            "shave.\" \n",
            "\"Oh, you like it. I'm so very good at it, Bran.\" He smiled and gave an awkward nod and \n",
            "Page 484\n",
            "\n",
            "dropped to the floor. The sun was out at midday. \n",
            "\"I'll do anything for you, Father, but I am not old enough to give you the care you deserve.\" \n",
            "\"What kind of wife are you to go in with me to look after Mother and me and your father?\" \n",
            "The godswife touched Ned's cheek, drawing the round shape of a silver crown. \"I am eighteen. I have a son, not \n",
            "yet twenty. But I should be thirty, if I had been allowed to keep you a son.\" \n",
            "\"Then you are your brother's,\" Ned said, smiling. \"Your brother has been a warrior my whole life. And . . \n",
            ". . what's the matter with you, Ned? How old is your brother now, you and Bran? What's he been \n",
            "complaining all this time?\" \n",
            "\"A great many things,\" Ned answered, \"and I've confessed to a great many things. Father's a great man, for \n",
            "he gave me his\n",
            "\n",
            "[201 | 477.32] loss=2.58 avg=2.75\n",
            "[202 | 479.56] loss=2.52 avg=2.74\n",
            "[203 | 481.80] loss=2.44 avg=2.74\n",
            "[204 | 484.04] loss=2.58 avg=2.74\n",
            "[205 | 486.28] loss=2.49 avg=2.74\n",
            "[206 | 488.52] loss=2.61 avg=2.73\n",
            "[207 | 490.77] loss=2.73 avg=2.73\n",
            "[208 | 493.00] loss=2.38 avg=2.73\n",
            "[209 | 495.24] loss=2.66 avg=2.73\n",
            "[210 | 497.48] loss=2.66 avg=2.73\n",
            "[211 | 499.71] loss=2.74 avg=2.73\n",
            "[212 | 501.96] loss=2.44 avg=2.73\n",
            "[213 | 504.20] loss=2.55 avg=2.72\n",
            "[214 | 506.44] loss=2.53 avg=2.72\n",
            "[215 | 508.68] loss=2.43 avg=2.72\n",
            "[216 | 510.91] loss=2.47 avg=2.72\n",
            "[217 | 513.15] loss=2.58 avg=2.71\n",
            "[218 | 515.39] loss=2.49 avg=2.71\n",
            "[219 | 517.62] loss=2.52 avg=2.71\n",
            "[220 | 519.86] loss=2.73 avg=2.71\n",
            "[221 | 522.09] loss=2.60 avg=2.71\n",
            "[222 | 524.32] loss=2.39 avg=2.70\n",
            "[223 | 526.56] loss=2.59 avg=2.70\n",
            "[224 | 528.79] loss=2.50 avg=2.70\n",
            "[225 | 531.03] loss=2.55 avg=2.70\n",
            "[226 | 533.26] loss=2.39 avg=2.70\n",
            "[227 | 535.49] loss=2.69 avg=2.70\n",
            "[228 | 537.73] loss=2.59 avg=2.69\n",
            "[229 | 539.96] loss=2.44 avg=2.69\n",
            "[230 | 542.20] loss=2.53 avg=2.69\n",
            "[231 | 544.43] loss=2.46 avg=2.69\n",
            "[232 | 546.66] loss=2.50 avg=2.69\n",
            "[233 | 548.89] loss=2.41 avg=2.68\n",
            "[234 | 551.13] loss=2.34 avg=2.68\n",
            "[235 | 553.37] loss=2.39 avg=2.68\n",
            "[236 | 555.60] loss=2.51 avg=2.67\n",
            "[237 | 557.83] loss=2.49 avg=2.67\n",
            "[238 | 560.07] loss=2.28 avg=2.67\n",
            "[239 | 562.31] loss=2.40 avg=2.66\n",
            "[240 | 564.54] loss=2.66 avg=2.66\n",
            "[241 | 566.78] loss=2.55 avg=2.66\n",
            "[242 | 569.01] loss=2.41 avg=2.66\n",
            "[243 | 571.24] loss=2.47 avg=2.66\n",
            "[244 | 573.48] loss=2.56 avg=2.66\n",
            "[245 | 575.72] loss=2.61 avg=2.66\n",
            "[246 | 577.96] loss=2.36 avg=2.65\n",
            "[247 | 580.20] loss=2.57 avg=2.65\n",
            "[248 | 582.43] loss=2.41 avg=2.65\n",
            "[249 | 584.67] loss=2.36 avg=2.65\n",
            "[250 | 586.91] loss=2.76 avg=2.65\n",
            "[251 | 589.15] loss=2.65 avg=2.65\n",
            "[252 | 591.39] loss=2.43 avg=2.65\n",
            "[253 | 593.63] loss=2.55 avg=2.64\n",
            "[254 | 595.87] loss=2.39 avg=2.64\n",
            "[255 | 598.10] loss=2.45 avg=2.64\n",
            "[256 | 600.35] loss=2.33 avg=2.64\n",
            "[257 | 602.59] loss=2.32 avg=2.63\n",
            "[258 | 604.83] loss=2.49 avg=2.63\n",
            "[259 | 607.06] loss=2.36 avg=2.63\n",
            "[260 | 609.29] loss=2.40 avg=2.63\n",
            "[261 | 611.54] loss=2.29 avg=2.62\n",
            "[262 | 613.78] loss=2.22 avg=2.62\n",
            "[263 | 616.02] loss=2.46 avg=2.62\n",
            "[264 | 618.25] loss=2.37 avg=2.61\n",
            "[265 | 620.50] loss=2.43 avg=2.61\n",
            "[266 | 622.74] loss=2.60 avg=2.61\n",
            "[267 | 624.98] loss=2.46 avg=2.61\n",
            "[268 | 627.22] loss=2.41 avg=2.61\n",
            "[269 | 629.46] loss=2.28 avg=2.60\n",
            "[270 | 631.70] loss=2.38 avg=2.60\n",
            "[271 | 633.94] loss=2.50 avg=2.60\n",
            "[272 | 636.18] loss=2.28 avg=2.60\n",
            "[273 | 638.41] loss=2.42 avg=2.60\n",
            "[274 | 640.65] loss=2.27 avg=2.59\n",
            "[275 | 642.89] loss=2.49 avg=2.59\n",
            "[276 | 645.13] loss=2.41 avg=2.59\n",
            "[277 | 647.37] loss=2.28 avg=2.59\n",
            "[278 | 649.61] loss=2.37 avg=2.58\n",
            "[279 | 651.85] loss=2.49 avg=2.58\n",
            "[280 | 654.09] loss=2.31 avg=2.58\n",
            "[281 | 656.32] loss=2.37 avg=2.58\n",
            "[282 | 658.56] loss=2.39 avg=2.58\n",
            "[283 | 660.81] loss=2.51 avg=2.57\n",
            "[284 | 663.05] loss=2.18 avg=2.57\n",
            "[285 | 665.29] loss=2.38 avg=2.57\n",
            "[286 | 667.52] loss=2.42 avg=2.57\n",
            "[287 | 669.76] loss=2.27 avg=2.56\n",
            "[288 | 672.00] loss=2.43 avg=2.56\n",
            "[289 | 674.24] loss=2.32 avg=2.56\n",
            "[290 | 676.47] loss=2.20 avg=2.56\n",
            "[291 | 678.71] loss=2.33 avg=2.55\n",
            "[292 | 680.94] loss=2.34 avg=2.55\n",
            "[293 | 683.18] loss=1.95 avg=2.54\n",
            "[294 | 685.42] loss=2.34 avg=2.54\n",
            "[295 | 687.66] loss=2.28 avg=2.54\n",
            "[296 | 689.90] loss=2.29 avg=2.54\n",
            "[297 | 692.13] loss=2.27 avg=2.53\n",
            "[298 | 694.37] loss=2.50 avg=2.53\n",
            "[299 | 696.60] loss=2.48 avg=2.53\n",
            "[300 | 698.84] loss=2.46 avg=2.53\n",
            "======== SAMPLE 1 ========\n",
            ". \n",
            "The Greatjon brought a fresh meat from the butcher's and the fat of an apple and placed it in the center of the \n",
            "meat baste on the plate. The apple was a tender and savory sweet brown with a tiny orange. There \n",
            "was nothing to taste but the sweetness of the juice left on the apple juice. The meat had to be cooked. \n",
            "In the center of the meat baste, the Greatjon turned the meat. His hand moved briskly aside, as he \n",
            "Page 50\n",
            "\n",
            "should. \n",
            "The meat made a sound. A head bobbed and shuddered as one, a soft hum of salt, pepper and lemon and \n",
            "pepper; the other two were more like a clang on a steel fist. Both men laughed, the Greatjon hissed and kicked \n",
            "his horse over the edge, and the Greatjon laughed louder. \n",
            "His son spoke as he had done: \"The Greatjon sent away our king now, and we all know which one \n",
            "is our king.\" \n",
            "\"My lord father is not our king,\" Ser Kevan protested. \"How could he command this cruel, unwholesome slaughter?\" \n",
            "A hand touched the meat baste on the far side of the meat baster, and he shook his head. \"The men \n",
            "said it was done to make our kingships more fit for war, and to test our honor and show the \n",
            "men that we were willing to die if sent. \n",
            "\"Now we know that all this was done to honor us. I will tell you what we learned from your little battle, \n",
            "Ser Brynden.\" \n",
            "A dark shadow touched the stone of his breast. \n",
            "He put a hand to the side of his body, stroked an icy throat. \"I will speak to my father in secret. Tell him \n",
            "that we took him with us, as we have done with all our other men. Tell him to honor the king that sent \n",
            "it, as we will.\" \n",
            "\"Lord Eddard is no king,\" Arya said. \"He took no captive. Nor was any man. All of us. We \n",
            "were men in need of men of his word to defend. Now we know that he commands honor from us. He \n",
            "commanded this thing we took. He gave that we were men. Now that we know, we must fight it out against King Robert himself.\" \n",
            "The Greatjon frowned. \"Your brother?\" \n",
            "Ser Brynden shrugged. \"Yes.\" \n",
            "\"Lord Eddard wants us to fight this off,\" Arya said. \"There was no way we could not send him here.\" \n",
            "\"I will be going, to give him a taste of our own medicine. A hundred silver pieces of \n",
            "polished silver and forty pounds of gold, my great-grandfather taught him.\" \n",
            "\"As promised, you sent him,\" Arya said. She'd been training him for half a day to be a healer. The \n",
            "man had no fear of leaving Arya, but her father had not spoken a word. \n",
            "Now he would have to. \"And you have sent one of Robert's men?\" \n",
            "\"Robert.\" Ser Brynden gave a nervous shake of his head. \"No.\" \n",
            "\"I sent him.\" \n",
            "The Greatjon took a deep breath and pulled his face away from Arya's voice, but it was so different to the other, \n",
            "so different now. \"In truth, he was sent, to see that the khal and his lords bannermen were not troubled, but the \n",
            "king was not. The lord commander is Robert, Lord Karstark. The khaleesi commander is Lord Varys.\" \n",
            "\"Varys, Lord Karstark,\" Arya replied. \n",
            "\"And you sent Jaime Lannister.\" She'd never heard Varys speak before, not a word of it. \n",
            "\"Jaime has no place in this,\" the Greatjon said. \"He must be killed.\" \n",
            "\"Jaime does,\" Arya admitted, trying to remember the last time Arya had held the Greatjon hostage. She had \n",
            "beneath a flat stone screen, where the men sat down on a bench and watched the kingsman \n",
            "with a sudden curiosity. She remembered her father. Perhaps he had taught her too \n",
            "strong a lesson. \n",
            "\"Joffrey,\" the Greatjon shouted, from the screen. \"Joffrey and his lords bannermen are \n",
            "coming, and they will not be allowed to leave this side of the road until they are . . . a good \n",
            "enough rider, I hear them. I shall leave one day. I have decided that the place is my to see, and \n",
            "I shall lead the others on, the two men each serving two masters.\" \n",
            "\n",
            "[301 | 711.91] loss=2.06 avg=2.53\n",
            "[302 | 714.15] loss=2.37 avg=2.53\n",
            "[303 | 716.38] loss=2.20 avg=2.52\n",
            "[304 | 718.61] loss=2.49 avg=2.52\n",
            "[305 | 720.85] loss=2.19 avg=2.52\n",
            "[306 | 723.08] loss=2.34 avg=2.52\n",
            "[307 | 725.31] loss=2.26 avg=2.51\n",
            "[308 | 727.55] loss=2.22 avg=2.51\n",
            "[309 | 729.78] loss=2.34 avg=2.51\n",
            "[310 | 732.01] loss=2.23 avg=2.51\n",
            "[311 | 734.25] loss=2.41 avg=2.51\n",
            "[312 | 736.48] loss=2.17 avg=2.50\n",
            "[313 | 738.71] loss=2.15 avg=2.50\n",
            "[314 | 740.95] loss=2.33 avg=2.50\n",
            "[315 | 743.18] loss=2.27 avg=2.49\n",
            "[316 | 745.42] loss=2.30 avg=2.49\n",
            "[317 | 747.65] loss=2.27 avg=2.49\n",
            "[318 | 749.89] loss=2.49 avg=2.49\n",
            "[319 | 752.12] loss=2.33 avg=2.49\n",
            "[320 | 754.36] loss=2.36 avg=2.49\n",
            "[321 | 756.59] loss=2.40 avg=2.49\n",
            "[322 | 758.83] loss=2.19 avg=2.48\n",
            "[323 | 761.07] loss=2.21 avg=2.48\n",
            "[324 | 763.30] loss=2.09 avg=2.48\n",
            "[325 | 765.54] loss=2.57 avg=2.48\n",
            "[326 | 767.77] loss=2.41 avg=2.48\n",
            "[327 | 770.01] loss=2.21 avg=2.47\n",
            "[328 | 772.25] loss=2.43 avg=2.47\n",
            "[329 | 774.48] loss=2.17 avg=2.47\n",
            "[330 | 776.73] loss=2.40 avg=2.47\n",
            "[331 | 778.96] loss=2.24 avg=2.47\n",
            "[332 | 781.20] loss=1.90 avg=2.46\n",
            "[333 | 783.44] loss=2.31 avg=2.46\n",
            "[334 | 785.67] loss=2.18 avg=2.46\n",
            "[335 | 787.91] loss=2.07 avg=2.45\n",
            "[336 | 790.15] loss=2.09 avg=2.45\n",
            "[337 | 792.38] loss=2.38 avg=2.45\n",
            "[338 | 794.62] loss=2.12 avg=2.44\n",
            "[339 | 796.85] loss=2.19 avg=2.44\n",
            "[340 | 799.09] loss=2.14 avg=2.44\n",
            "[341 | 801.33] loss=2.27 avg=2.44\n",
            "[342 | 803.57] loss=2.31 avg=2.44\n",
            "[343 | 805.81] loss=2.18 avg=2.43\n",
            "[344 | 808.05] loss=2.19 avg=2.43\n",
            "[345 | 810.28] loss=2.30 avg=2.43\n",
            "[346 | 812.52] loss=2.03 avg=2.42\n",
            "[347 | 814.77] loss=2.35 avg=2.42\n",
            "[348 | 817.00] loss=2.10 avg=2.42\n",
            "[349 | 819.24] loss=1.97 avg=2.42\n",
            "[350 | 821.48] loss=2.22 avg=2.41\n",
            "[351 | 823.72] loss=2.17 avg=2.41\n",
            "[352 | 825.95] loss=2.19 avg=2.41\n",
            "[353 | 828.18] loss=2.01 avg=2.41\n",
            "[354 | 830.42] loss=2.12 avg=2.40\n",
            "[355 | 832.65] loss=2.15 avg=2.40\n",
            "[356 | 834.89] loss=1.85 avg=2.39\n",
            "[357 | 837.12] loss=2.01 avg=2.39\n",
            "[358 | 839.36] loss=1.95 avg=2.39\n",
            "[359 | 841.60] loss=2.26 avg=2.38\n",
            "[360 | 843.84] loss=2.11 avg=2.38\n",
            "[361 | 846.08] loss=2.02 avg=2.38\n",
            "[362 | 848.32] loss=2.09 avg=2.37\n",
            "[363 | 850.56] loss=2.24 avg=2.37\n",
            "[364 | 852.79] loss=2.25 avg=2.37\n",
            "[365 | 855.04] loss=2.00 avg=2.37\n",
            "[366 | 857.27] loss=2.27 avg=2.37\n",
            "[367 | 859.52] loss=2.13 avg=2.36\n",
            "[368 | 861.75] loss=2.27 avg=2.36\n",
            "[369 | 863.99] loss=2.29 avg=2.36\n",
            "[370 | 866.23] loss=2.36 avg=2.36\n",
            "[371 | 868.47] loss=2.13 avg=2.36\n",
            "[372 | 870.71] loss=2.32 avg=2.36\n",
            "[373 | 872.95] loss=1.98 avg=2.36\n",
            "[374 | 875.18] loss=1.74 avg=2.35\n",
            "[375 | 877.42] loss=2.10 avg=2.35\n",
            "[376 | 879.67] loss=2.39 avg=2.35\n",
            "[377 | 881.91] loss=2.34 avg=2.35\n",
            "[378 | 884.14] loss=2.14 avg=2.35\n",
            "[379 | 886.38] loss=2.06 avg=2.34\n",
            "[380 | 888.61] loss=2.14 avg=2.34\n",
            "[381 | 890.86] loss=2.00 avg=2.34\n",
            "[382 | 893.10] loss=2.33 avg=2.34\n",
            "[383 | 895.34] loss=2.18 avg=2.34\n",
            "[384 | 897.57] loss=2.13 avg=2.33\n",
            "[385 | 899.81] loss=2.09 avg=2.33\n",
            "[386 | 902.05] loss=2.36 avg=2.33\n",
            "[387 | 904.30] loss=1.95 avg=2.33\n",
            "[388 | 906.54] loss=2.06 avg=2.32\n",
            "[389 | 908.78] loss=2.08 avg=2.32\n",
            "[390 | 911.02] loss=2.06 avg=2.32\n",
            "[391 | 913.26] loss=2.32 avg=2.32\n",
            "[392 | 915.51] loss=2.03 avg=2.32\n",
            "[393 | 917.75] loss=1.90 avg=2.31\n",
            "[394 | 919.98] loss=1.90 avg=2.31\n",
            "[395 | 922.22] loss=2.10 avg=2.31\n",
            "[396 | 924.47] loss=1.96 avg=2.30\n",
            "[397 | 926.71] loss=2.06 avg=2.30\n",
            "[398 | 928.95] loss=1.74 avg=2.29\n",
            "[399 | 931.19] loss=2.00 avg=2.29\n",
            "[400 | 933.43] loss=2.19 avg=2.29\n",
            "======== SAMPLE 1 ========\n",
            "danger and sudden. He saw a man with grey hair, a \n",
            "honeymoon on his face, and he gave him a tight hug. \"Sweet boy,\" Bran said. \n",
            "\"He wanted to see you.\" Ned said, \"You're so kind. I hope he finds you strong, Ned.\" \n",
            "\"I have a boy for myself.\" Ned laughed. It was a laugh so raw that Ned did not seem to understand. \n",
            "His arm was already sore, when he heard the door slam. \n",
            "Lord Tywin had come to see him.,,,,.,.,,.,:,.,:,.,,.,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,., ,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,.,,., 1. Bran had not told him all of what had just happened. If he had, Tyrion would know . . . if only he had the strength left over from their \n",
            "rounings south of the Neck. \n",
            "\"The Wall is a terrible thing to behold, the direwolf of old meandering through Winterfell, my brothers,\" the Lord Commander \n",
            "said. \"I remember those days with me. I never had the courage to look out\n",
            "\n",
            "[401 | 946.43] loss=1.91 avg=2.29\n",
            "[402 | 948.66] loss=2.11 avg=2.28\n",
            "[403 | 950.90] loss=1.87 avg=2.28\n",
            "[404 | 953.15] loss=1.90 avg=2.28\n",
            "[405 | 955.39] loss=2.17 avg=2.28\n",
            "[406 | 957.63] loss=2.17 avg=2.27\n",
            "[407 | 959.86] loss=1.90 avg=2.27\n",
            "[408 | 962.10] loss=2.12 avg=2.27\n",
            "[409 | 964.35] loss=1.73 avg=2.26\n",
            "[410 | 966.59] loss=2.08 avg=2.26\n",
            "[411 | 968.82] loss=1.88 avg=2.26\n",
            "[412 | 971.06] loss=2.05 avg=2.26\n",
            "[413 | 973.29] loss=1.94 avg=2.25\n",
            "[414 | 975.54] loss=1.98 avg=2.25\n",
            "[415 | 977.78] loss=1.83 avg=2.25\n",
            "[416 | 980.02] loss=2.09 avg=2.24\n",
            "[417 | 982.27] loss=2.08 avg=2.24\n",
            "[418 | 984.50] loss=1.85 avg=2.24\n",
            "[419 | 986.75] loss=2.19 avg=2.24\n",
            "[420 | 988.99] loss=2.03 avg=2.24\n",
            "[421 | 991.24] loss=1.97 avg=2.23\n",
            "[422 | 993.48] loss=1.89 avg=2.23\n",
            "[423 | 995.71] loss=1.95 avg=2.23\n",
            "[424 | 997.95] loss=1.86 avg=2.22\n",
            "[425 | 1000.20] loss=2.04 avg=2.22\n",
            "[426 | 1002.45] loss=1.64 avg=2.21\n",
            "[427 | 1004.69] loss=2.05 avg=2.21\n",
            "[428 | 1006.93] loss=1.98 avg=2.21\n",
            "[429 | 1009.17] loss=1.59 avg=2.20\n",
            "[430 | 1011.42] loss=1.87 avg=2.20\n",
            "[431 | 1013.67] loss=2.31 avg=2.20\n",
            "[432 | 1015.91] loss=1.94 avg=2.20\n",
            "[433 | 1018.14] loss=1.56 avg=2.19\n",
            "[434 | 1020.38] loss=2.03 avg=2.19\n",
            "[435 | 1022.63] loss=1.95 avg=2.19\n",
            "[436 | 1024.88] loss=2.00 avg=2.19\n",
            "[437 | 1027.12] loss=1.75 avg=2.18\n",
            "[438 | 1029.36] loss=1.85 avg=2.18\n",
            "[439 | 1031.60] loss=1.84 avg=2.18\n",
            "[440 | 1033.84] loss=2.00 avg=2.17\n",
            "[441 | 1036.09] loss=2.03 avg=2.17\n",
            "[442 | 1038.33] loss=2.10 avg=2.17\n",
            "[443 | 1040.57] loss=2.00 avg=2.17\n",
            "[444 | 1042.81] loss=1.64 avg=2.17\n",
            "[445 | 1045.05] loss=2.09 avg=2.16\n",
            "[446 | 1047.29] loss=1.93 avg=2.16\n",
            "[447 | 1049.54] loss=1.89 avg=2.16\n",
            "[448 | 1051.78] loss=2.29 avg=2.16\n",
            "[449 | 1054.02] loss=1.99 avg=2.16\n",
            "[450 | 1056.26] loss=1.87 avg=2.16\n",
            "[451 | 1058.50] loss=2.08 avg=2.16\n",
            "[452 | 1060.73] loss=1.76 avg=2.15\n",
            "[453 | 1062.98] loss=1.98 avg=2.15\n",
            "[454 | 1065.22] loss=1.94 avg=2.15\n",
            "[455 | 1067.45] loss=1.68 avg=2.14\n",
            "[456 | 1069.69] loss=2.00 avg=2.14\n",
            "[457 | 1071.93] loss=1.69 avg=2.14\n",
            "[458 | 1074.18] loss=2.17 avg=2.14\n",
            "[459 | 1076.42] loss=1.72 avg=2.13\n",
            "[460 | 1078.66] loss=1.96 avg=2.13\n",
            "[461 | 1080.89] loss=2.18 avg=2.13\n",
            "[462 | 1083.13] loss=1.78 avg=2.13\n",
            "[463 | 1085.37] loss=1.81 avg=2.12\n",
            "[464 | 1087.61] loss=1.85 avg=2.12\n",
            "[465 | 1089.85] loss=1.74 avg=2.12\n",
            "[466 | 1092.09] loss=1.91 avg=2.12\n",
            "[467 | 1094.32] loss=1.52 avg=2.11\n",
            "[468 | 1096.56] loss=1.84 avg=2.11\n",
            "[469 | 1098.80] loss=1.76 avg=2.10\n",
            "[470 | 1101.04] loss=1.95 avg=2.10\n",
            "[471 | 1103.27] loss=1.94 avg=2.10\n",
            "[472 | 1105.50] loss=1.79 avg=2.10\n",
            "[473 | 1107.74] loss=1.95 avg=2.10\n",
            "[474 | 1109.98] loss=1.72 avg=2.09\n",
            "[475 | 1112.22] loss=2.26 avg=2.09\n",
            "[476 | 1114.45] loss=1.71 avg=2.09\n",
            "[477 | 1116.69] loss=2.02 avg=2.09\n",
            "[478 | 1118.92] loss=1.91 avg=2.09\n",
            "[479 | 1121.16] loss=1.75 avg=2.08\n",
            "[480 | 1123.40] loss=1.64 avg=2.08\n",
            "[481 | 1125.63] loss=1.85 avg=2.08\n",
            "[482 | 1127.87] loss=1.73 avg=2.07\n",
            "[483 | 1130.10] loss=1.54 avg=2.07\n",
            "[484 | 1132.34] loss=1.81 avg=2.07\n",
            "[485 | 1134.58] loss=1.69 avg=2.06\n",
            "[486 | 1136.81] loss=1.53 avg=2.06\n",
            "[487 | 1139.04] loss=1.80 avg=2.05\n",
            "[488 | 1141.27] loss=1.52 avg=2.05\n",
            "[489 | 1143.50] loss=1.86 avg=2.05\n",
            "[490 | 1145.74] loss=1.82 avg=2.04\n",
            "[491 | 1147.97] loss=1.91 avg=2.04\n",
            "[492 | 1150.20] loss=1.69 avg=2.04\n",
            "[493 | 1152.42] loss=1.74 avg=2.04\n",
            "[494 | 1154.65] loss=1.86 avg=2.03\n",
            "[495 | 1156.88] loss=1.78 avg=2.03\n",
            "[496 | 1159.11] loss=1.61 avg=2.03\n",
            "[497 | 1161.35] loss=1.77 avg=2.03\n",
            "[498 | 1163.57] loss=1.98 avg=2.02\n",
            "[499 | 1165.81] loss=1.66 avg=2.02\n",
            "[500 | 1168.04] loss=2.05 avg=2.02\n",
            "Saving checkpoint/run1/model-500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Text generation"
      ],
      "metadata": {
        "id": "bUagiJzBTeoL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prefix = \"What is after death?\""
      ],
      "metadata": {
        "id": "qzTK7bdIPeOY"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpt2.generate(sess, prefix=prefix, length=500)"
      ],
      "metadata": {
        "id": "ZCaaNXR7kI9I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c758a0d1-dea7-4928-c42a-cbcdaa2ca0fe"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What is after death? \n",
            "\"I can see it. The sky is so clear, and all the stars are pointing in the same direction, so it makes \n",
            "me wonder.\" \n",
            "\"Is it a dream?\" Catelyn Stark asked softly. It did not seem to her that it was a dream. \n",
            "\"You will wake soon enough,\" the king said. His eyes were red from sleep, but his mouth was \n",
            "smiling and smiling. \n",
            "\"I will go down to the crypt, and bring you good wine,\" the king said. \"Sweet woman, you will make a \n",
            "brilliant friend. If you do, I shall be sure to bring you some silver for your wedding.\" \n",
            "Her handmaids helped her from the crypt, and \n",
            "Catelyn Stark took her to the top of a low, stone arch of the mountain range. Inside was a small \n",
            "haunted place, a great high and narrow, where the dead lay buried and frozen. The walls were \n",
            "underfoot, bare and unbreakable. The dead still beat against the stone wall, moaning and \n",
            "screaming for warmth. The dead were always cold. The only sound was the bellowing of the direwolf \n",
            "crows, who were ever so wary of light that they would not even open their eyes to see the light. \n",
            "Inside the crypt, the sound was like music to Catelyn's ears. The shadows were coming up on her \n",
            "Page 126\n",
            "\n",
            "ear, bawling at her as they came, and howling in her sleep as her horse struggled to a stop. She \n",
            "could hear the soft softwooden rumbling in the dark, the soft woodleaves of the grass, the distant voices of the \n",
            "great grasshopper and the great white-faced man in the snow. She could also hear the \n",
            "spearheaded man in the snow, the great white-faced man in the snow cloak, and there was no mistaking it \n",
            "for anything but the message in the shadows moving through the dark wood. Catelyn knew what it meant \n",
            "to live in a dream, yet the words seemed to rush out at her, a thousand voices whispering in her ears, \n",
            "and she could not hear them. \n",
            "Her handmaids helped her from the crypt, and the king had a second hand. He was a hollow man \n",
            "who\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Saving model to Google Drive (optional)"
      ],
      "metadata": {
        "id": "zlM6aQYZSccl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYXmOFl5Bjhv",
        "outputId": "8cb884d2-4b9b-4657-c749-d01b1859e89d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpt2.copy_checkpoint_to_gdrive(run_name='run1')"
      ],
      "metadata": {
        "id": "3RUjr4_ZluKi"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can find more texts e.g. on:\n",
        "https://www.gutenberg.org/cache/epub/1597/pg1597.txt\n",
        "</br></br>\n",
        "You can download them to Colab using code similar to the ones below."
      ],
      "metadata": {
        "id": "OUhaGg_uS6o5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!wget https://www.gutenberg.org/cache/epub/1597/pg1597.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7K9X3K8TEwj",
        "outputId": "d0760c42-a0e4-4dcf-b7cc-ca98aaffa2b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-21 14:49:16--  https://www.gutenberg.org/cache/epub/1597/pg1597.txt\n",
            "Resolving www.gutenberg.org (www.gutenberg.org)... 152.19.134.47, 2610:28:3090:3000:0:bad:cafe:47\n",
            "Connecting to www.gutenberg.org (www.gutenberg.org)|152.19.134.47|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 329071 (321K) [text/plain]\n",
            "Saving to: â€˜pg1597.txtâ€™\n",
            "\n",
            "pg1597.txt          100%[===================>] 321.36K   800KB/s    in 0.4s    \n",
            "\n",
            "2023-03-21 14:49:22 (800 KB/s) - â€˜pg1597.txtâ€™ saved [329071/329071]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!wget https://www.gutenberg.org/files/98/98-0.txt"
      ],
      "metadata": {
        "id": "HYL0wij2m4Gf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42bf360b-ce90-4a36-d434-44820124b877"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-02-22 13:25:10--  https://www.gutenberg.org/files/98/98-0.txt\n",
            "Resolving www.gutenberg.org (www.gutenberg.org)... 152.19.134.47, 2610:28:3090:3000:0:bad:cafe:47\n",
            "Connecting to www.gutenberg.org (www.gutenberg.org)|152.19.134.47|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 807231 (788K) [text/plain]\n",
            "Saving to: â€˜98-0.txtâ€™\n",
            "\n",
            "98-0.txt            100%[===================>] 788.31K   718KB/s    in 1.1s    \n",
            "\n",
            "2023-02-22 13:25:12 (718 KB/s) - â€˜98-0.txtâ€™ saved [807231/807231]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#https://github.com/matt-dray/tng-stardate/tree/master/data/scripts"
      ],
      "metadata": {
        "id": "VClsbkgRxYvR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}